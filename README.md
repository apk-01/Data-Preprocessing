# Data-Preprocessing
This repository explores the various standard ways of data preprocessing

Data preporcessing is the most important part of data mining, which we do before data analysis.

Data preprocessing techniques include:

1. Data cleaning: Removing missing data and smooth the noisy data.
2. Data transformation: To transform data to the appropriate form.
3. Data reduction: To reduce data storage costs.

The codes are written on : google colaboratory (https://colab.research.google.com/notebooks/intro.ipynb)

To execute the codes locally:

1. Set up anaconda
2. Add python 3.6+
3. Remove google colab file uploading cell from the notebook
4. Install the dependencies(imported libraries) before executing the program
5. Execute the code with your own data/images

To execute with google colab:

1. Upload your own data/images while executing the upload cell
2. Replace the file reading file names with your image file names
3. Execute the remaining cells

# Handling missing data

This is a data cleaning technique. Missing data are often part of raw datasets. To handle such missing data, we can perform various techniques such as: dropping tuples having null data, replacing the data, and so on. We shall explore some of these methods.

# Normalization of data

This is a data transformation technique used to convert data from various sources or values of different ranges into a common range. There are few standard techniques to perform these operations and we shall look at them in this project.
